{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first concept of the perceptron was published by Frank Rosenblatt, he proposed an algorithm that would automatically learn the optimal weight coefficients that are then multiplied with the input features in order to make the decision of whether a neuron fires or not. In the context of supervised learning and classification, such an algorithm could then be used to predict if a sample belonged to one class or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can describe a problem as having two classes 1 (positive class) and -1 (negative class) then we can define an *activation function* $\\phi(z)$ that takes a linear combination of input values $X$ and input weights $W$ where $z$ is the net input. \n",
    "\n",
    "$$\n",
    "W = \n",
    "\\begin{bmatrix}\n",
    "    W_{1} \\\\\n",
    "    \\vdots \\\\\n",
    "    W_{m} \\\\\n",
    "\\end{bmatrix}\n",
    ",\\\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "    X_{1} \\\\\n",
    "    \\vdots \\\\\n",
    "    X_{m} \\\\\n",
    "\\end{bmatrix}\n",
    ".$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the input values $X$ to describe the features of a datapoint and the input weights to be the consideration that each feature gets. Each iteration the weights will be updated if an incorrect prediction is calculated thus, they are updated by learning from the data.\n",
    "\n",
    "The net input is the combination of input values and weights that correspond to the same feature defined as such \n",
    "$$z = w_1x_1 + \\dots + w_mx_m.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, once we have the net input $z$ of a particular sample $x^i$ (the ith sample) the last step is to compare against a defined threshold $\\theta$. If $z$ is greater than $\\theta$ then the perceptron would fire (1), otherwise the perceptron would remain dormant (-1). In the case of the perceptron model, the activation function $\\phi(z)$ becomes a simple step function. This is also referred to as the *Heaviside step function*.\n",
    "\n",
    "$$\\phi(z) = \n",
    "\\begin{cases} \n",
    "      \\nobreakspace{} \\nobreakspace{} 1 & if z \\geq \\theta \\\\\n",
    "      -1 & otherwise\n",
    "   \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can simplify the activation function my moving the threshold $\\theta$ to the left side of the equation and defining a weight-zero as $w_0 = -\\theta$ and $x_0 = 1$. The activation function now reads, \n",
    "\n",
    "$$\n",
    "z = w_0x_0 + w_ix_i + \\dots + w_mx_m = w^Tx \n",
    "$$\n",
    "\n",
    "<center>and</center>\n",
    "\n",
    "\n",
    "$$\n",
    "\\phi(z) = \n",
    "\\begin{cases} \n",
    "      \\nobreakspace{} \\nobreakspace{} 1 & if z \\geq 0 \\\\\n",
    "      -1 & otherwise\n",
    "   \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By creating another input weight combo denoted by $w_0x_0$ we can take the treshold into account for each datapoint and still simplify the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The perceptron model can be used to descriminate between two linearly separable classes by condensing the input $X$ combined with weights $W$ into a net input $z$ and then using the activation function to condense the net input into a Boolean true (1), false (-1) output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Rosenblatt's whole idea with the perceptron model is to use a reductionist approach to how a single neuron in the brain works: it either fires or it doesn't. The initail perceptron rule is failry simple:\n",
    "1. Initialize the weights to 0 or small random numbers.\n",
    "2. For each traigin example **$x^i$** perform the following steps:\n",
    "    1. Comput the output value $\\hat{y}$.\n",
    "    2. Update the weights\n",
    "    \n",
    "The output value will be the class label prediction from the perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "During training, everytime that the class label prediction is wrong we need to update the weights to adjust for that sample. The weight for a feature is not the same weight combined with the change in weight.\n",
    "$$w_j := w_j + \\Delta w_j$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The change in weight can be calculated by ther perceptron learning rule:\n",
    "\n",
    "$$\n",
    "\\Delta w_j = \\eta \\left(y^\\left(i\\right) - \\hat{y}^\\left(i\\right)\\right) x_j^\\left(i\\right)\n",
    "$$\n",
    "\n",
    "The change in weight can be read as the difference between actual label and the predicted label, multiplied by the input and the learning rate $\\eta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to note is that convergence is only possible if the data is linearly separable. By convergence we mean that the model can predict with 100% accuracy after being trained. Without a convergence the model would never stop updating it's weights to account for mislabled predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron model described here can be depicted as such. All inputs have a corresponding weight, they are all paired and combined in the net input function, the threshold function activates the perceptron if the output fron the input function is greater than the threshold, and finally if the prediction is wrong (activated when it shouldn't have and vice versa) then the weights are updated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![perceptron-flow](./images/perceptron-flow.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
