{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"a-dev.dist.txt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets:  1663\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(datafile, na_values='', encoding='utf-8')\n",
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.fillna('')\n",
    "tweets = df.as_matrix()[:, :]\n",
    "\n",
    "print(\"number of tweets: \", len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkmark 3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "# nltk.download()\n",
    "\n",
    "# Create features\n",
    "def features(sentence):\n",
    "    sentence = re.sub('<[^>]*>', '', sentence)\n",
    "    #Remove hyperlinks\n",
    "    sentence = re.sub(r\"http\\S+\", '', sentence, flags=re.MULTILINE)\n",
    "    #Remove quotes\n",
    "    sentence = re.sub(r'&amp;quot;|&amp;amp', '', sentence)\n",
    "    #Remove citations\n",
    "    sentence = re.sub(r'(@[a-zA-Z0-9])\\w*', '', sentence)\n",
    "    #Remove hashtags\n",
    "    sentence = re.sub(r'(#[a-zA-Z0-9])\\w*', '', sentence)\n",
    "    #Remove tickers\n",
    "    sentence = re.sub(r'\\$[a-zA-Z0-9]*', '', sentence)\n",
    "    #Remove numbers\n",
    "    sentence = re.sub(r'[0-9]*','',sentence)\n",
    "    \n",
    "\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', sentence.lower())\n",
    "    sentence = re.sub('[\\W]+', ' ', sentence.lower()) +        ' '.join(emoticons).replace('-', '')\n",
    "    \n",
    "    stop_words = stopwords.words('english') + list(punctuation)\n",
    "    words = word_tokenize(sentence)\n",
    "    words = [w.lower() for w in words]\n",
    "    filtered = [w for w in words if w not in stop_words and not w.isdigit()]\n",
    "    words = {}\n",
    "    for word in filtered:\n",
    "        if word in words:\n",
    "            words[word] += 1.0\n",
    "        else:\n",
    "            words[word] = 1.0\n",
    "    return words\n",
    "\n",
    "print(\"checkmark 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkmark 4\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the features function\n",
    "features = np.vectorize(features)\n",
    "# Extract the features for the whole dataset\n",
    "X = features(tweets[:, 1])\n",
    "# Set the targets\n",
    "y = tweets[:, 0]\n",
    "\n",
    "print(\"checkmark 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 11 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8382441371016236\n",
      "Optimized parameters:  Pipeline(memory=None,\n",
      "     steps=[('dct', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=True)), ('svc', LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "Best CV score:  0.7372218881539386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 110 out of 110 | elapsed:    4.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create grid search\n",
    "clf = Pipeline([(\"dct\", DictVectorizer()), (\"svc\", LinearSVC())])\n",
    "params = {\n",
    "    \"svc__C\": [1e15, 1e13, 1e11, 1e9, 1e7, 1e5, 1e3, 1e1, 1e-1, 1e-3, 1e-5]\n",
    "}\n",
    "gs = GridSearchCV(clf, params, cv=10, verbose=1, n_jobs=-1, refit=True)\n",
    "gs.fit(X, y)\n",
    "model = gs.best_estimator_\n",
    "\n",
    "# Print results\n",
    "print(model.score(X, y))\n",
    "print(\"Optimized parameters: \", model)\n",
    "print(\"Best CV score: \", gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "\n",
    "# Convert to CoreML model\n",
    "coreml_model = coremltools.converters.sklearn.convert(model)\n",
    "coreml_model.author = 'Cameron Deardorff'\n",
    "coreml_model.license = 'MIT'\n",
    "coreml_model.short_description = 'Sentiment polarity LinearSVC.'\n",
    "coreml_model.input_description['input'] = 'Features extracted from the text.'\n",
    "coreml_model.output_description['classLabel'] = 'The most likely polarity (positive/neutral/negative), for the given input.'\n",
    "coreml_model.output_description['classProbability'] = 'The probabilities for each class label, for the given input.'\n",
    "coreml_model.save('SentimentPolarity.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.dist\n",
    "# Best CV score:  0.8073365433350228"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
